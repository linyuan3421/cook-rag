import os
import sys
import time
import logging
import streamlit as st
from dotenv import load_dotenv

# --- 1. åŸºç¡€é…ç½®ä¸åˆå§‹åŒ– ---
st.set_page_config(
    page_title="å°å°å’¸æ·¡ AI",
    page_icon="ğŸ³",
    layout="wide",
    initial_sidebar_state="expanded"
)

load_dotenv()

if not os.getenv("DASHSCOPE_API_KEY"):
    st.error("ğŸš¨ é”™è¯¯: æœªæ£€æµ‹åˆ° DASHSCOPE_API_KEYï¼Œè¯·æ£€æŸ¥ .env æ–‡ä»¶ã€‚")
    st.stop()

sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

try:
    from rag_modules.data_preparation import DataPreparationModule
    from rag_modules.index_construction import IndexConstructionModule
    from rag_modules.retrieval_optimization import RetrievalOptimizationModule
    from rag_modules.generation_integration import GenerationIntegrationModule
    from config import DEFAULT_CONFIG
except ImportError as e:
    st.error(f"âŒ æ ¸å¿ƒæ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
    st.stop()

logging.getLogger("langchain_core").setLevel(logging.WARNING)

# --- 2. æ ¸å¿ƒç³»ç»ŸåŠ è½½ (å¸¦ç¼“å­˜) ---
@st.cache_resource(show_spinner=False)
def load_rag_system():
    """åˆå§‹åŒ–å¹¶ç¼“å­˜RAGç³»ç»Ÿ"""
    try:
        data_module = DataPreparationModule(data_path=DEFAULT_CONFIG.data_path)
        data_module.load_and_process_documents()
        
        index_module = IndexConstructionModule(
            model_name=DEFAULT_CONFIG.embedding_model,
            index_save_path=DEFAULT_CONFIG.index_save_path
        )
        vectorstore = index_module.load_or_build_index(data_module.chunks)
        
        retrieval_module = RetrievalOptimizationModule(vectorstore, data_module.chunks)
        
        generation_module = GenerationIntegrationModule(
            model_name=DEFAULT_CONFIG.llm_model,
            temperature=DEFAULT_CONFIG.temperature,
            max_tokens=DEFAULT_CONFIG.max_tokens
        )
        
        return {
            "data": data_module,
            "retrieval": retrieval_module,
            "generation": generation_module,
            "status": "ready"
        }
    except Exception as e:
        return {"status": "error", "message": str(e)}

def format_references(docs):
    """è¾…åŠ©å‡½æ•°ï¼šå°†æ–‡æ¡£å¯¹è±¡è½¬æ¢ä¸ºæ˜“äºå±•ç¤ºå’Œå­˜å‚¨çš„å­—å…¸åˆ—è¡¨"""
    if not docs:
        return []
    refs = []
    for doc in docs:
        refs.append({
            "dish": doc.metadata.get("dish_name", "æœªçŸ¥èœå“"),
            "category": doc.metadata.get("category", "å…¶ä»–"),
            "difficulty": doc.metadata.get("difficulty", "æœªçŸ¥"),
            "source": os.path.basename(doc.metadata.get("source", ""))
        })
    return refs

# --- 3. ä¾§è¾¹æ  ---
with st.sidebar:
    st.image("https://img.icons8.com/color/96/cooking-pot.png", width=80)
    st.title("å°å°å’¸æ·¡ AI")
    st.caption("æ‚¨çš„ç§äººæ™ºèƒ½è†³é£Ÿé¡¾é—®")
    st.divider()
    
    if "rag_system" not in st.session_state:
        with st.status("ğŸš€ ç³»ç»Ÿæ­£åœ¨å¯åŠ¨...", expanded=True) as status:
            st.write("æ­£åœ¨åŠ è½½èœè°±æ•°æ®...")
            rag = load_rag_system()
            if rag["status"] == "ready":
                st.session_state.rag_system = rag
                st.write("ç´¢å¼•æ„å»ºå®Œæˆ...")
                status.update(label="âœ… ç³»ç»Ÿå°±ç»ª", state="complete", expanded=False)
            else:
                st.error(f"ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {rag['message']}")
                st.stop()
    
    rag = st.session_state.rag_system
    st.metric(label="å·²æ”¶å½•èœè°±", value=f"{len(rag['data'].documents)} é“")
    st.divider()
    
    if st.button("ğŸ—‘ï¸ æ¸…ç©ºå¯¹è¯å†å²", use_container_width=True):
        st.session_state.messages = []
        st.rerun()

# --- 4. ä¸»èŠå¤©ç•Œé¢ ---

if "messages" not in st.session_state:
    st.session_state.messages = [
        {"role": "assistant", "content": "ä½ å¥½ï¼æˆ‘æ˜¯å°å½“å®¶ã€‚ä»Šå¤©æƒ³åƒç‚¹ä»€ä¹ˆï¼Ÿ"}
    ]

# æ¸²æŸ“å†å²æ¶ˆæ¯ (å…³é”®ä¿®æ”¹ï¼šå¢åŠ å¼•ç”¨æ¸²æŸ“)
for msg in st.session_state.messages:
    avatar = "ğŸ³" if msg["role"] == "assistant" else "ğŸ§‘â€ğŸ’»"
    with st.chat_message(msg["role"], avatar=avatar):
        st.markdown(msg["content"])
        
        # å¦‚æœè¯¥æ¶ˆæ¯åŒ…å«å¼•ç”¨ä¿¡æ¯ï¼Œåˆ™æ¸²æŸ“æŠ˜å æ¡†
        if "references" in msg and msg["references"]:
            with st.expander("ğŸ“š å‚è€ƒé£Ÿè°± / æ¥æº"):
                for i, ref in enumerate(msg["references"]):
                    st.markdown(f"**{i+1}. {ref['dish']}**")
                    st.caption(f"åˆ†ç±»: {ref['category']} | éš¾åº¦: {ref['difficulty']} | æ–‡ä»¶: `{ref['source']}`")

# å¤„ç†ç”¨æˆ·è¾“å…¥
if prompt := st.chat_input("è¾“å…¥æ‚¨çš„é—®é¢˜..."):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user", avatar="ğŸ§‘â€ğŸ’»"):
        st.markdown(prompt)

    with st.chat_message("assistant", avatar="ğŸ³"):
        message_placeholder = st.empty()
        full_response = ""
        relevant_docs = [] # åˆå§‹åŒ–
        
        with st.status("ğŸ³ æ­£åœ¨æ€è€ƒä¸­...", expanded=False) as status:
            try:
                rag = st.session_state.rag_system
                
                st.write("ğŸ¤” åˆ†æç”¨æˆ·æ„å›¾...")
                route_type = rag["generation"].query_router(prompt)
                
                st.write("âœï¸ ä¼˜åŒ–æŸ¥è¯¢å…³é”®è¯...")
                rewritten_query = rag["generation"].query_rewrite(prompt)
                
                st.write("ğŸ” åˆ†æç­›é€‰æ¡ä»¶...")
                filters = rag["generation"].extract_filters(prompt, rag["data"])
                
                st.write("ğŸ“š æ£€ç´¢çŸ¥è¯†åº“...")
                relevant_chunks = []
                if filters:
                    relevant_chunks = rag["retrieval"].metadata_filtered_search(
                        rewritten_query, filters, top_k=5
                    )
                    if not relevant_chunks:
                        st.write("âš ï¸ è¿‡æ»¤æ£€ç´¢æ— ç»“æœï¼Œé™çº§ä¸ºæ··åˆæ£€ç´¢...")
                        relevant_chunks = rag["retrieval"].hybrid_search(rewritten_query, top_k=5)
                else:
                    relevant_chunks = rag["retrieval"].hybrid_search(rewritten_query, top_k=5)
                
                relevant_docs = rag["data"].get_parent_documents(relevant_chunks)
                status.update(label="âœ¨ æ€è€ƒå®Œæˆ", state="complete", expanded=False)
                
            except Exception as e:
                status.update(label="âŒ å‘ç”Ÿé”™è¯¯", state="error")
                st.error(f"å¤„ç†æµç¨‹å¼‚å¸¸: {e}")
                st.stop()

        try:
            if not relevant_docs:
                full_response = "æŠ±æ­‰ï¼Œæˆ‘çš„èœè°±åº“é‡Œæš‚æ—¶æ²¡æœ‰æ‰¾åˆ°ç›¸å…³å†…å®¹ã€‚"
                message_placeholder.markdown(full_response)
                # å³ä½¿æ²¡æœ‰æ‰¾åˆ°ï¼Œä¹Ÿä¿å­˜ä¸€æ¡ç©ºå¼•ç”¨çš„æ¶ˆæ¯
                st.session_state.messages.append({
                    "role": "assistant", 
                    "content": full_response,
                    "references": []
                })
            else:
                response_generator = rag["generation"].generate_answer(
                    prompt, relevant_docs, route_type
                )
                
                for chunk in response_generator:
                    full_response += chunk
                    message_placeholder.markdown(full_response + "â–Œ")
                
                message_placeholder.markdown(full_response)
                
                # --- æ ¸å¿ƒä¿®æ”¹ï¼šå¤„ç†å¹¶å±•ç¤ºå¼•ç”¨ ---
                # 1. æ ¼å¼åŒ–å¼•ç”¨æ•°æ®
                refs_data = format_references(relevant_docs)
                
                # 2. åœ¨å½“å‰å›ç­”ä¸‹æ–¹ç«‹å³å±•ç¤º
                if refs_data:
                    with st.expander("ğŸ“š å‚è€ƒé£Ÿè°± / æ¥æº"):
                        for i, ref in enumerate(refs_data):
                            st.markdown(f"**{i+1}. {ref['dish']}**")
                            st.caption(f"åˆ†ç±»: {ref['category']} | éš¾åº¦: {ref['difficulty']} | æ–‡ä»¶: `{ref['source']}`")

                # 3. ä¿å­˜åˆ°å†å²è®°å½• (åŒ…å«å¼•ç”¨æ•°æ®)
                st.session_state.messages.append({
                    "role": "assistant", 
                    "content": full_response,
                    "references": refs_data
                })
        
        except Exception as e:
            st.error(f"ç”Ÿæˆå›ç­”æ—¶å‡ºé”™: {e}")