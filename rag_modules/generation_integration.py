# rag_modules/generation_integration.py

import os
import json
import logging
from typing import List, Dict, Any, Iterator

from langchain_core.prompts import ChatPromptTemplate
from langchain_core.language_models.chat_models import BaseChatModel
from langchain_community.chat_models.tongyi import ChatTongyi
from langchain_core.documents import Document
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnableLambda
# å¯¼å…¥ DataPreparationModule ä»¥è¿›è¡Œç±»å‹æ³¨è§£
from .data_preparation import DataPreparationModule 

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class GenerationIntegrationModule:
    """
    ç”Ÿæˆé›†æˆæ¨¡å—ï¼Œç”¨äºå¤„ç†ç”¨æˆ·æŸ¥è¯¢å¹¶ç”Ÿæˆç­”æ¡ˆã€‚
    æ ¸å¿ƒèŒè´£ï¼š
    1.  åˆå§‹åŒ–å¤§è¯­è¨€æ¨¡å‹ (LLM)ã€‚
    2.  æ™ºèƒ½è·¯ç”±ï¼šæ ¹æ®ç”¨æˆ·é—®é¢˜åˆ†ç±»æ„å›¾ã€‚
    3.  æŸ¥è¯¢é‡å†™ï¼šå¯¹æ¨¡ç³Šé—®é¢˜è¿›è¡Œä¼˜åŒ–ã€‚
    4.  å¤šæ¨¡å¼ç”Ÿæˆï¼šæ ¹æ®æ„å›¾é€‰æ‹©ä¸åŒçš„Promptå’Œç”Ÿæˆç­–ç•¥ã€‚
    5.  æ”¯æŒæµå¼è¾“å‡ºï¼Œæå‡ç”¨æˆ·ä½“éªŒã€‚
    """

    def __init__(self, model_name: str = "qwen-plus-latest", temperature: float = 0.1, max_tokens: int = 4096):
        self.model_name = model_name
        self.temperature = temperature
        self.max_tokens = max_tokens
        self.llm: BaseChatModel = None
        self._setup_llm()

    def _setup_llm(self):
        """ç§æœ‰æ–¹æ³•ï¼Œåˆå§‹åŒ–å¤§è¯­è¨€æ¨¡å‹ã€‚"""
        logger.info(f"æ­£åœ¨åˆå§‹åŒ–LLM: {self.model_name}")
        api_key = os.getenv("DASHSCOPE_API_KEY")
        if not api_key:
            raise ValueError("ç¯å¢ƒå˜é‡ DASHSCOPE_API_KEY æœªè®¾ç½®ï¼Œè¯·åœ¨.envæ–‡ä»¶ä¸­é…ç½®ã€‚")
        self.llm = ChatTongyi(
            model=self.model_name,
            temperature=self.temperature,
            max_tokens=self.max_tokens,
            dashscope_api_key=api_key
        )
        logger.info("LLMåˆå§‹åŒ–å®Œæˆã€‚")

    def query_router(self, query: str) -> str:
        """ä½¿ç”¨LLMå¯¹ç”¨æˆ·æŸ¥è¯¢è¿›è¡Œæ„å›¾åˆ†ç±»ã€‚"""
        prompt = ChatPromptTemplate.from_template("""æ ¹æ®ç”¨æˆ·çš„èœè°±æŸ¥è¯¢é—®é¢˜ï¼Œå°†å…¶åˆ†ç±»ä¸ºä»¥ä¸‹ä¸‰ç§ç±»å‹ä¹‹ä¸€ï¼š
        1. 'list': å½“ç”¨æˆ·æƒ³è¦è·å–ä¸€ä¸ªèœå“åˆ—è¡¨æˆ–æ¨èæ—¶ã€‚ä¾‹å¦‚ï¼š"æ¨èå‡ ä¸ªç´ èœ"ã€"æœ‰ä»€ä¹ˆç®€å•çš„æ—©é¤"ã€‚
        2. 'detail': å½“ç”¨æˆ·è¯¢é—®ç‰¹å®šèœå“çš„åˆ¶ä½œæ–¹æ³•ã€é£Ÿææˆ–æ­¥éª¤æ—¶ã€‚ä¾‹å¦‚ï¼š"å®«ä¿é¸¡ä¸æ€ä¹ˆåš"ã€"ç•ªèŒ„ç‚’è›‹éœ€è¦ä»€ä¹ˆåŸæ–™"ã€‚
        3. 'general': å½“é—®é¢˜ä¸å±äºä»¥ä¸Šä¸¤ç±»ï¼Œå¯èƒ½æ˜¯ä¸€èˆ¬æ€§çŸ¥è¯†ã€çƒ¹é¥ªæŠ€å·§æˆ–æ¨¡ç³Šä¸æ¸…æ—¶ã€‚ä¾‹å¦‚ï¼š"ä»€ä¹ˆæ˜¯å·èœ"ã€"å¦‚ä½•è®©é¸¡è‚‰æ›´å«©"ã€‚

        è¯·åªè¿”å›'list'ã€'detail'æˆ–'general'è¿™ä¸‰ä¸ªå•è¯ä¸­çš„ä¸€ä¸ªã€‚

        ç”¨æˆ·é—®é¢˜: "{query}"
        åˆ†ç±»ç»“æœ:""")
        
        chain = prompt | self.llm | StrOutputParser()
        result = chain.invoke({"query": query}).strip().lower()
        
        logger.info(f"æŸ¥è¯¢ '{query}' çš„è·¯ç”±ç±»å‹åˆ¤å®šä¸º: {result}")
        return result if result in ['list', 'detail', 'general'] else 'general'

    def query_rewrite(self, query: str) -> str:
        """å¯¹æ¨¡ç³ŠæŸ¥è¯¢è¿›è¡Œé‡å†™ï¼Œä½¿å…¶æ›´é€‚åˆæ£€ç´¢ã€‚"""
        prompt = ChatPromptTemplate.from_template(
        """ä½ æ˜¯ä¸€ä¸ªæŸ¥è¯¢ä¼˜åŒ–åŠ©æ‰‹ã€‚ä½ çš„ç›®æ ‡æ˜¯å°†ç”¨æˆ·çš„ã€æ¨¡ç³Šæ„å›¾ã€‘è½¬åŒ–ä¸ºæ•°æ®åº“èƒ½å¬æ‡‚çš„ã€å…·ä½“é£Ÿææˆ–èœåã€‘ã€‚

        æˆ‘ä»¬çš„æ•°æ®åº“æ˜¯ä¸€ä¸ªã€ç¾é£Ÿèœè°±åº“ã€‘ï¼ŒåŒ…å«å…·ä½“çš„åˆ¶ä½œæ­¥éª¤ã€‚å®ƒ**ä¸åŒ…å«**è¥å…»å­¦æ ‡ç­¾ï¼ˆå¦‚"å‡è‚¥"ã€"å¥èº«"ï¼‰æˆ–åœºæ™¯æ ‡ç­¾ï¼ˆå¦‚"å®´å®¢"ï¼‰ã€‚

        ### é‡å†™ç­–ç•¥:
        1.  **åœºæ™¯è½¬é£Ÿæ:** å¦‚æœç”¨æˆ·é—®åœºæ™¯ï¼ˆå¥èº«ã€å‡è‚¥ã€ç”Ÿç—…ï¼‰ï¼Œè¯·é‡å†™ä¸ºé€‚åˆè¯¥åœºæ™¯çš„**å…·ä½“é£Ÿæ**æˆ–**çƒ¹é¥ªæ–¹å¼**ã€‚
        2.  **æ¨¡ç³Šè½¬å…·ä½“:** å¦‚æœç”¨æˆ·é—®"å¥½åƒçš„"ï¼Œé‡å†™ä¸º"çƒ­é—¨å®¶å¸¸èœ"ã€‚
        3.  **ä¿æŒåŸæ„:** å¦‚æœç”¨æˆ·å·²ç»é—®äº†å…·ä½“çš„èœï¼ˆ"å®«ä¿é¸¡ä¸"ï¼‰ï¼Œä¸è¦æ”¹ã€‚

        ### ç¤ºä¾‹:
        - åŸ: "å¥èº«æœŸé—´åƒä»€ä¹ˆ" -> æ–°: "é¸¡èƒ¸è‚‰ ç‰›è‚‰ è™¾ é±¼ æ¸…æ·¡åšæ³•" (ç¿»è¯‘æˆé«˜è›‹ç™½é£Ÿæ)
        - åŸ: "å‡è‚¥é¤" -> æ–°: "å‡‰æ‹Œèœ è”¬èœæ²™æ‹‰ ä½è„‚ é¸¡è‚‰"
        - åŸ: "é€‚åˆè€äººçš„èœ" -> æ–°: "ç‚–èœ ç²¥ è½¯çƒ‚ æ˜“æ¶ˆåŒ–"
        - åŸ: "æœ‰ä»€ä¹ˆä¸‹é¥­èœ" -> æ–°: "å›é”…è‚‰ éº»å©†è±†è… çº¢çƒ§è‚‰ è¾£"
        - åŸ: "åšèœ" -> æ–°: "ç®€å•æ˜“åšçš„ç¾é£Ÿèœè°±"

        åŸå§‹æŸ¥è¯¢: "{query}"
        ä¼˜åŒ–åçš„æŸ¥è¯¢:""")

        chain = prompt | self.llm | StrOutputParser()
        rewritten_query = chain.invoke({"query": query}).strip()
        
        logger.info(f"æŸ¥è¯¢é‡å†™: '{query}' â†’ '{rewritten_query}'")
        return rewritten_query
    
    def generate_list_answer(self, context_docs: List[Document]) -> str:
        """å¯¹äº'list'ç±»å‹çš„æŸ¥è¯¢ï¼Œç›´æ¥ä»å…ƒæ•°æ®ç”Ÿæˆç®€æ´çš„èœå“åˆ—è¡¨ã€‚"""
        if not context_docs:
            return "æŠ±æ­‰ï¼Œæ ¹æ®æ‚¨çš„æè¿°ï¼Œæˆ‘æ²¡æœ‰æ‰¾åˆ°ç›¸å…³çš„èœå“æ¨èã€‚"

        dish_names = [doc.metadata.get('dish_name', 'æœªçŸ¥èœå“') for doc in context_docs]
        # ç®€å•å»é‡
        dish_names = list(dict.fromkeys(dish_names))
        
        if not dish_names:
             return "æŠ±æ­‰ï¼Œæœªèƒ½ä»ç›¸å…³ä¿¡æ¯ä¸­æå–å‡ºèœå“åç§°ã€‚"
        response = "ä¸ºæ‚¨æ¨èä»¥ä¸‹èœå“ï¼š\n" + "\n".join([f"  - {name}" for name in dish_names])
        return response

    def _build_context(self, docs: List[Document], max_length: int = 3500) -> str:
        """æ„å»ºç”¨äºç”Ÿæˆç­”æ¡ˆçš„ä¸Šä¸‹æ–‡å­—ç¬¦ä¸²ï¼ŒåŒ…å«å…ƒæ•°æ®å’Œé•¿åº¦æ§åˆ¶ã€‚"""
        context_parts = []
        current_length = 0
        
        for doc in docs:
            metadata_header = f"--- é£Ÿè°±: {doc.metadata.get('dish_name', 'N/A')} | åˆ†ç±»: {doc.metadata.get('category', 'N/A')} | éš¾åº¦: {doc.metadata.get('difficulty', 'N/A')} ---\n"
            doc_text = metadata_header + doc.page_content
            
            if current_length + len(doc_text) > max_length:
                remaining_len = max_length - current_length
                context_parts.append(doc_text[:remaining_len] + "...")
                break
            
            context_parts.append(doc_text)
            current_length += len(doc_text)
        
        return "\n\n".join(context_parts)

    def get_prompt_template(self, route_type: str) -> str:
        """æ ¹æ®è·¯ç”±ç±»å‹ï¼Œè¿”å›å¯¹åº”çš„Promptæ¨¡æ¿å­—ç¬¦ä¸²ã€‚"""
        if route_type == 'detail':
            return """ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„çƒ¹é¥ªå¯¼å¸ˆã€‚è¯·æ ¹æ®ä¸‹é¢æä¾›çš„é£Ÿè°±ä¿¡æ¯ï¼Œç²¾å‡†å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚

        ### å›ç­”åŸåˆ™ï¼ˆè‡³å…³é‡è¦ï¼‰ï¼š
        1. **ç›´å‡»ç—›ç‚¹**ï¼šå¦‚æœç”¨æˆ·è¯¢é—®çš„æ˜¯**å…·ä½“ç»†èŠ‚**ï¼ˆå¦‚â€œæ¯”ä¾‹æ˜¯å¤šå°‘â€ã€â€œéœ€è¦ç„¯æ°´å—â€ã€â€œç…®å¤šä¹…â€ï¼‰ï¼Œè¯·**ç›´æ¥ã€æ­£é¢åœ°å›ç­”è¯¥é—®é¢˜**ï¼Œå¹¶å¼•ç”¨ä¸Šä¸‹æ–‡ä¸­çš„å…³é”®æ•°æ®ä½è¯ã€‚**ç»å¯¹ä¸è¦**è¾“å‡ºæ— å…³çš„å®Œæ•´é£Ÿè°±ç»“æ„æˆ–åºŸè¯ã€‚
        2. **å®Œæ•´æ•™å­¦**ï¼šåªæœ‰å½“ç”¨æˆ·æ˜ç¡®è¯¢é—®**æ•´ä½“åšæ³•**ï¼ˆå¦‚â€œæ€ä¹ˆåšâ€ã€â€œåˆ¶ä½œæ­¥éª¤â€ã€â€œæ•™æˆ‘åšè¿™ä¸ªâ€ï¼‰æ—¶ï¼Œæ‰ä½¿ç”¨ä»¥ä¸‹ç»“æ„åŒ–æ ¼å¼ï¼š
           ### ğŸ¥˜ èœå“ä»‹ç»
           ### ğŸ›’ æ‰€éœ€é£Ÿæ
           ### ğŸ‘¨â€ğŸ³ åˆ¶ä½œæ­¥éª¤
           ### ğŸ’¡ åˆ¶ä½œæŠ€å·§

        è¯·ä¸¥æ ¼åŸºäºæä¾›çš„ä¸Šä¸‹æ–‡ä½œç­”ã€‚

        ---
        ä¸Šä¸‹æ–‡é£Ÿè°±ä¿¡æ¯:
        {context}
        ---
        ç”¨æˆ·é—®é¢˜: "{question}"

        ä½ çš„å›ç­”:
        """
        else:  # general
            return """ä½ æ˜¯ä¸€ä½å‹å–„çš„çƒ¹é¥ªåŠ©æ‰‹ã€‚è¯·æ ¹æ®ä¸‹é¢æä¾›çš„ç›¸å…³é£Ÿè°±ä¿¡æ¯ï¼Œç®€æ´ã€ç›´æ¥åœ°å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚å¦‚æœä¿¡æ¯ä¸è¶³ï¼Œè¯·è¯šå®å‘ŠçŸ¥ã€‚

        ---
        ç›¸å…³é£Ÿè°±ä¿¡æ¯:
        {context}
        ---
        ç”¨æˆ·é—®é¢˜: "{question}"

        ä½ çš„å›ç­”:
        """

    def _get_generation_chain(self, prompt_template: str) -> Any:
        """è¾…åŠ©å‡½æ•°ï¼Œæ ¹æ®Promptæ¨¡æ¿æ„å»ºä¸€ä¸ªæ ‡å‡†çš„LCELç”Ÿæˆé“¾ã€‚"""
        return (
            {
                "context": lambda x: self._build_context(x["context_docs"]),
                "question": lambda x: x["query"]
            }
            | ChatPromptTemplate.from_template(prompt_template)
            | self.llm
            | StrOutputParser()
        )

    def generate_answer(self, query: str, context_docs: List[Document], route_type: str) -> Iterator[str]:
        """
        ç»Ÿä¸€çš„ç”Ÿæˆå…¥å£ï¼Œæ ¹æ®è·¯ç”±ç±»å‹é€‰æ‹©ä¸åŒçš„ç”Ÿæˆç­–ç•¥ï¼Œå¹¶æ”¯æŒæµå¼è¾“å‡ºã€‚
        """
        if route_type == 'list':
            # å¯¹äºlistç±»å‹ï¼Œéœ€è¦é€å­—ç¬¦yieldä»¥ç¡®ä¿æµå¼è¾“å‡ºæ­£å¸¸å·¥ä½œ
            response = self.generate_list_answer(context_docs)
            for char in response:
                yield char
            return

        prompt_template = self.get_prompt_template(route_type)
        chain = self._get_generation_chain(prompt_template)
        
        # ä½¿ç”¨.stream()æ–¹æ³•ç¡®ä¿æµå¼è¾“å‡ºæ­£å¸¸å·¥ä½œ
        for chunk in chain.stream({"query": query, "context_docs": context_docs}):
            yield chunk


    
    def extract_filters(self, query: str, data_module: DataPreparationModule) -> dict:
        # 1. è·å–åŠ¨æ€åˆ†ç±»åˆ—è¡¨
        dynamic_categories = list(data_module.available_categories.values())
        
        # 2. åœ¨Pythonå±‚é¢æ„å»ºæè¿°å­—ç¬¦ä¸²
        metadata_description = f"""
        ä½ å¯ä»¥æ ¹æ®ä»¥ä¸‹å­—æ®µè¿›è¡Œè¿‡æ»¤ï¼š
        
        - `category`: èœå“åˆ†ç±»ã€‚å¯é€‰å€¼ä¸å®šä¹‰å¦‚ä¸‹ï¼š
            - 'æ—©é¤': **åŒ…å«é¸¡è›‹ã€ç‰ç±³ã€çº¢è–¯ã€ç²¥ã€é¦’å¤´ã€åå¸ç­‰æ—©æ™¨å¸¸åƒçš„é£Ÿç‰©ã€‚** (æ³¨æ„ï¼šç…®ç‰ç±³ã€èŒ¶å¶è›‹å±äºæ­¤åˆ—ï¼Œè€Œéä¸»é£Ÿæˆ–è¤èœ)
            - 'ä¸»é£Ÿ': æŒ‡æ­£é¤çš„ä¸»é£Ÿï¼Œå¦‚ç±³é¥­ã€é¢æ¡ã€é¥ºå­ã€ç‚’é¥­ã€ç‚’é¢ã€é¥¼ã€‚
            - 'è¤èœ': ä»¥è‚‰ç±»ï¼ˆçŒªç‰›ç¾Šé¸¡é¸­ï¼‰ä¸ºä¸»è¦é£Ÿæçš„èœè‚´ã€‚
            - 'ç´ èœ': ä»¥è”¬èœã€è±†åˆ¶å“ã€èŒè‡ä¸ºä¸»è¦é£Ÿæçš„èœè‚´ã€‚
            - 'æ°´äº§': é±¼ã€è™¾ã€èŸ¹ã€è´ç±»ã€‚
            - 'æ±¤ä¸ç²¥': å„ç§æ±¤ç±»å’Œæ­£é¤ç²¥å“ã€‚
            - 'ç”œå“': è›‹ç³•ã€é¥¼å¹²ã€ç³–æ°´ã€‚
            - 'é¥®æ–™': é¥®å“ã€é…’æ°´ã€‚
            - 'åŠæˆå“åŠ å·¥': é€Ÿå†»é£Ÿå“ã€ç©ºæ°”ç‚¸é”…åŠæˆå“ã€‚
            
        - `difficulty`: çƒ¹é¥ªéš¾åº¦ã€‚å¯é€‰å€¼ï¼š['éå¸¸ç®€å•', 'ç®€å•', 'ä¸­ç­‰', 'å›°éš¾', 'éå¸¸å›°éš¾', 'æœªçŸ¥']ã€‚
        """
        
        # 3. ä¿®æ”¹ Promptï¼šç›´æ¥ä½¿ç”¨ {metadata_description}
        prompt = ChatPromptTemplate.from_template("""ä½ æ˜¯ä¸€ä¸ªæŸ¥è¯¢è§£æä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯ä»ç”¨æˆ·çš„æŸ¥è¯¢ä¸­ï¼Œæå–**æ˜ç¡®çš„**å…ƒæ•°æ®è¿‡æ»¤æ¡ä»¶ã€‚

        ### å¯ç”¨çš„å…ƒæ•°æ®å­—æ®µåŠå…¶è¯´æ˜:
        {metadata_description}

        ### âš ï¸ é‡è¦åŸåˆ™ (å¿…é¡»ä¸¥æ ¼éµå®ˆ):
        1.  **ä¸è¦æ¨æ–­ï¼ä¸è¦æ¨æ–­ï¼** åªæœ‰å½“ç”¨æˆ·**æ˜¾å¼**æåˆ°äº†ä¸Šè¿°å¯é€‰å€¼ä¸­çš„è¯æ±‡ï¼ˆæˆ–å…¶ç²¾ç¡®åŒä¹‰è¯ï¼‰æ—¶ï¼Œæ‰æå–è¯¥æ¡ä»¶ã€‚
        2.  **åœºæ™¯ä¸é£Ÿæä¸æ˜¯åˆ†ç±»ï¼š** 
            - å¦‚æœç”¨æˆ·è¯´ "å¥èº«"ã€"å‡è‚¥"ã€"å®´å®¢"ï¼Œ**ä¸è¦**æå– categoryã€‚
            - å¦‚æœç”¨æˆ·è¯´ "åœŸè±†"ã€"ç‰›è‚‰"ã€"é¸¡è›‹"ï¼Œ**ä¸è¦**æå– categoryã€‚
        3.  **å®ç¼ºæ¯‹æ»¥ï¼š** å¦‚æœä½ ä¸ç¡®å®šï¼Œæˆ–è€…ç”¨æˆ·åªæ˜¯åœ¨æè¿°ä¸€ç§æ¨¡ç³Šçš„æ„Ÿè§‰ï¼Œè¯·è¿”å›ç©ºå­—å…¸ `{{}}`ã€‚è®©æ£€ç´¢ç³»ç»Ÿé€šè¿‡è¯­ä¹‰å»åŒ¹é…ï¼Œæ¯”é”™è¯¯çš„è¿‡æ»¤æ›´å¥½ã€‚

        ### ç¤ºä¾‹:
        - "æ¨èä¸€é“ç®€å•çš„è¤èœæ±¤" -> {{"category": "æ±¤å“", "difficulty": "ç®€å•"}}
        - "å®¶é‡Œåªæœ‰é¸¡è›‹å’Œè¥¿çº¢æŸ¿" -> {{}}
        - "å¥èº«æœŸé—´åƒä»€ä¹ˆ" -> {{}}
        - "æœ‰ä»€ä¹ˆç´ èœ" -> {{"category": "ç´ èœ"}}

        ### ç”¨æˆ·æŸ¥è¯¢:
        "{query}"

        JSONè¾“å‡º:
        """)
        
        chain = prompt | self.llm | StrOutputParser()
        
        try:
            # 4. ç°åœ¨è¿™é‡Œä¼  metadata_description 
            response_str = chain.invoke({
                "query": query,
                "metadata_description": metadata_description 
            })
            
            # 5. è§£æJSON
            if "```json" in response_str:
                response_str = response_str.split("```json")[1].split("```")[0].strip()
            filters = json.loads(response_str)
            if not isinstance(filters, dict): return {}
            return filters
        except Exception as e:
            logger.error(f"è§£æè¿‡æ»¤å™¨JSONæ—¶å¤±è´¥: {e}")
            return {}